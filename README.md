# Static site generation (ssg) для ускорения сайта в 2-20 раз или важность кеширования

Думаю многие сталкивались со словом оптимизация в контексте работы с сайтами.
Эта оптимизация может быть на многих уровнях, но всегда говорят об оптимизации
сайтов и веб приложений затрагивают три основных аспекта:
1. Скорость ответа сервера
2. Вес ответа сервера
3. Затрачиваемые ресурсы на ответ

И если вес исправляется как правило эффективным сжатием, выбрасыванием не нужного,
то в этой статье мы рассмотрим как можно оптимизировать скорость ответа и
затрачиваемые ресурсы. 

Скорость ответа как правило зависит не столь от больших и важных бизнес задач,
или от количества ваших клиентов в данную секунду.
Высокая скорость ответа сервера как правило зависит от того, как хорошо и быстро отвечает
ваша база данный, и как скоро она отдаёт вам вашу информацию. Будь то простая статья вроде этой,
или интернет магазин, а может расчёт стоимости поездки в соседнюю страну по горячему туру.
И как правило для того что бы ускорить работу нашего сайта мы оптимизируем первым делом базу данных.
Оптимизация индексов, партицирования, самих запросов выступают своего рода первый уровнем,
тем с чего всё начинается - оптимизация программ.
Однако после первого уровня появляется второй - кеширование, ведь самый быстрый код / запрос тот, что не исполняется.
И с Этого момента открывается кроличья нора. Ибо кеш может перекрывать самые тяжёлые и важные операции,
или сохранят самые простые, но частые запросы, а может быть все объемлющим.
Мы можем кешировать работу целых отдельных сервисов, можем полностью подменять
их вызов на получение заранее подготовленного кеша, и ничего не терять в актуальности данных
(прим.: api дистанций меж городов) долгое время.
Но если мы можем подменять отдельные обращения к базе данных, и даже результаты работы каких-то сервисов,
то можем ли мы подменить работу целого приложения заранее заготовленным кешом?

Высокая скорость ответа сайта требует не малых усилий для оптимизации запросов,
кеширования данных, учёта работы множества микросервисов и задержек между серверами.
Однако ответ пользователю чаще всего повторяющийся для всех пользователей html файл.
Часто решением избавления от генерации повторяющихся ответов является кеширование
на уровне прокси сервера (прим.: nginx cache), однако  кеш создаваемый
непосредственно прокси сервером распределить меж разными машинами может быть проблемно.
Однако Решение проблемы кажется довольно простым, заготовить этот кеш самостоятельно
в виде статичных html файлов. Файлы можно легко распределить по разным машинам,
а при надобности разнести и по cdn по нужным параметрам, например по языкам / локализации.
Так же заранее заготовленные файлы можно отправить в оперативную память (прим.: memcached)
и ускорить доступ к html. Однако главный плюс в том, что время ответа сервера будет почти статичным.

Таким образом мы оптимизируем скорость ответа, а не обращаясь к веренице
сервисов и миркросервисов, и так же мы сокращаем бюджеты на ресурсы.

Перед тем как рассматривать примеры кода и конфигурации сервера для генерации стоит рассмотреть
## Альтернативные подходы
Существует уже не мало подходов к подготовке html файлов для пользователя.
- SPA и MPA
- SSR - в этот же пункт запишем любую полную генерацию страницы на лету, по запросу пользователя.
- island
И ниже я хотел бы кратко рассмотреть плюсы и минусы этих подходов
### SPA и MPA
Приложение и фактический рендер на стороне клиента.
У нас нет реальных страниц, нет реальной маршрутизации запросов на стороне сервера.
Это очень частый подход для написания бизнес приложений. Таблицы информации, дашборды с графиками,
множество форм. Это очень простой в поддержке и исполнении вариант для написания приложений и сайтов.
Минусы подхода большая нагрузка на браузер клиента, исторически считается что ужасная SEO
оптимизация, а так же большой итоговый вес сборки для пользователя. Иначе говоря это не то,
что вы хотели бы видеть в качестве основы вашего магазина товаров или услуг.
### SSR и иная генерация на лету
На самом деле классический вариант это генерация страницы на лету.
Будь то старый добрый index.php, или всем уже привычный ssr с использование nodejs,
это тот самый классический в наше время вариант когда на запрос пользователя каждый раз в итоге для ответа
создаётся html страница.
Этот формат имеет, как считается, лучшую SEO оптимизацию чем SPA / MPA вариант,
он позволяет на один и тот же запрос отвечать по разному, и конечно же даёт возможность на каждое обращение пользователя
выполнять какую бы то ни было бизнес логику на стороне сервера.
Минусы - самый первый, и наверное самый важный минус заключается в том что мы ждём, скажем так, дважды. Пока страница будет подготовлена на стороне сервера, и когда страница отобразится, и запустит свою внутреннюю javascript / wasm логику.
Ожидание ответа от сервера и является во многом тем самым ключевым моментом для оптимизации, и написания этой статьи.
Так же существенным минусом является выделение серверных мощностей на пускай и чаще всего быстрые, но не очень сильно необходимые
повторяющиеся из раза в раз действия - рендер html, и прочих частей сайта.

В эпоху cms многие пытались обойти повторный рендер внедрением компонентной структуры, что бы точно знать что можно переиспользовать,
умным кешем который сам отслеживал не изменяемые блоки и код который был за них ответственен.
Иначе говоря всеми способами пытались зонировать код на активный и не активный
### Island и Astro
https://github.com/11ty/is-land/
https://astro.build/
## Описание проекта ssg-example
Данный пример призван показать и объяснить вариации ssg на примере nuxt3.
А так же подсветить плюсы и минусы использования такого подхода.
В примере используется google books api, go как proxy backend, nuxt 3, и прочие технологии.

```bash
for file in `find ./**/*.tar`; do tar -s ',\\,/,g' -xf "${file}" -C ./; done
```